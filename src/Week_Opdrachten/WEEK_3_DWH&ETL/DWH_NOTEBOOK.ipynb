{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWH ETL Opdracht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operationele Databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connectie met SSMS voor SDM en DWH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_SDM = {\"servername\": r\"localhost,1433\", \"database\": \"sdm\", \"username\": \"sa\", \"password\": \"iDTyjZx7dRL4\"}\n",
    "DB_DWH = {\"servername\": r\"localhost,1433\", \"database\": \"dwh\", \"username\": \"sa\", \"password\": \"iDTyjZx7dRL4\"}\n",
    "\n",
    "\n",
    "import_conn = pyodbc.connect(\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={DB_SDM['servername']};\"\n",
    "    f\"DATABASE={DB_SDM['database']};\"\n",
    "    f\"UID={DB_SDM['username']};\"\n",
    "    f\"PWD={DB_SDM['password']}\"\n",
    ")\n",
    "\n",
    "export_conn = pyodbc.connect(\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={DB_DWH['servername']};\"\n",
    "    f\"DATABASE={DB_DWH['database']};\"\n",
    "    f\"UID={DB_DWH['username']};\"\n",
    "    f\"PWD={DB_DWH['password']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames maken voor tables (EXTRACT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/8yvf4x0n4c15r7pl4lwy8x6m0000gp/T/ipykernel_30532/913697658.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_names = pd.read_sql(query, connection)\n",
      "/var/folders/k4/8yvf4x0n4c15r7pl4lwy8x6m0000gp/T/ipykernel_30532/913697658.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sales_territory', 'country', 'order_method', 'retailer_site', 'sales_branch', 'sales_staff', 'retailer_contact', 'order_header', 'product_line', 'product_type', 'product', 'order_details', 'return_reason', 'returned_item', 'course', 'satisfaction_type', 'satisfaction', 'training', 'age_group', 'retailer_segment', 'retailer_headquarters', 'retailer_type', 'retailer', 'sales_demographic', 'inventory_levels', 'forecast']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k4/8yvf4x0n4c15r7pl4lwy8x6m0000gp/T/ipykernel_30532/913697658.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
      "/var/folders/k4/8yvf4x0n4c15r7pl4lwy8x6m0000gp/T/ipykernel_30532/913697658.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
      "/var/folders/k4/8yvf4x0n4c15r7pl4lwy8x6m0000gp/T/ipykernel_30532/913697658.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n"
     ]
    }
   ],
   "source": [
    "def create_dataframes_sql(connection):\n",
    "    dictionary : dict = {}\n",
    "    query : str = \"\"\n",
    "    key : str = \"\"\n",
    "\n",
    "    query = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE';\"\n",
    "    key = \"TABLE_NAME\"\n",
    "\n",
    "    table_names = pd.read_sql(query, connection)\n",
    "\n",
    "    for table in table_names[key].tolist():\n",
    "        dictionary[table] = pd.read_sql(f\"SELECT * FROM {table}\", connection)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "sdm = create_dataframes_sql(import_conn)\n",
    "\n",
    "print(list(sdm.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMeren van tables voor DWH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORDER_DETAILS TRANSFORM\n",
    "order_details = sdm[\"order_details\"]\n",
    "order_details = pd.merge(order_details, sdm[\"order_header\"], left_on=\"ORDER_NUMBER\", how=\"inner\", right_on=\"ORDER_NUMBER\")\n",
    "order_details = pd.merge(order_details, sdm[\"order_method\"], left_on=\"ORDER_METHOD_CODE\", how=\"inner\", right_on=\"ORDER_METHOD_CODE\")\n",
    "order_details = pd.merge(order_details, sdm[\"returned_item\"], left_on=\"ORDER_DETAIL_CODE\", how=\"inner\", right_on=\"ORDER_DETAIL_CODE\")\n",
    "order_details = order_details.drop(columns=[\"ORDER_NUMBER\", \"RETURN_CODE\", \"ORDER_METHOD_CODE\"])\n",
    "order_details[\"REVENUE\"] = order_details[\"UNIT_SALE_PRICE\"] * order_details[\"QUANTITY\"]\n",
    "order_details[\"TOTAL_COST\"] = order_details[\"UNIT_COST\"] * order_details[\"QUANTITY\"]\n",
    "\n",
    "#PRODUCT TRANSFORM\n",
    "product = sdm[\"product\"]\n",
    "product = pd.merge(product, sdm[\"product_type\"], left_on=\"PRODUCT_TYPE_CODE\", how=\"inner\", right_on=\"PRODUCT_TYPE_CODE\")\n",
    "product = pd.merge(product, sdm[\"product_line\"], left_on=\"PRODUCT_LINE_CODE\", how=\"inner\", right_on=\"PRODUCT_LINE_CODE\")\n",
    "product = product.drop(columns=[\"PRODUCT_TYPE_CODE\", \"PRODUCT_LINE_CODE\"])\n",
    "current_year = datetime.now().year\n",
    "product[\"PRODUCT_AGE\"] = current_year - (pd.to_datetime(product[\"INTRODUCTION_DATE\"]).dt.year)\n",
    "\n",
    "#RETAILER_SITE TRANSFORM\n",
    "retailer_site = sdm[\"retailer_site\"]\n",
    "retailer_site = pd.merge(retailer_site, sdm[\"country\"], left_on=\"COUNTRY_CODE\", how=\"inner\", right_on=\"COUNTRY_CODE\")\n",
    "retailer_site = retailer_site.drop(columns=[\"RETAILER_CODE\", \"COUNTRY_CODE\", \"FLAG_IMAGE\", \"SALES_TERRITORY_CODE\"])\n",
    "\n",
    "#SALES_STAFF TRANSFORM\n",
    "sales_staff = sdm[\"sales_staff\"]\n",
    "sales_staff[\"FULL_NAME\"] = sales_staff[\"FIRST_NAME\"] + \" \" + sales_staff[\"LAST_NAME\"]\n",
    "sales_staff = sales_staff.drop(columns=[\"FIRST_NAME\", \"LAST_NAME\", \"WORK_PHONE\", \"FAX\", \"EMAIL\"])\n",
    "sales_staff[\"YEARS_OF_EXPERIENCE\"] = current_year - (pd.to_datetime(sales_staff[\"DATE_HIRED\"]).dt.year)\n",
    "sales_staff\n",
    "\n",
    "dwh_dict = {\n",
    "    \"sales_staff\": sales_staff,\n",
    "    \"retailer_site\": retailer_site,\n",
    "    \"product\": product,\n",
    "    \"inventory_levels\": sdm[\"inventory_levels\"],\n",
    "    \"order_details\": order_details\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DWH database vullen (LOAD):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_cursor = export_conn.cursor()\n",
    "\n",
    "for table_name, df in dwh_dict.items():\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            columns = df.columns.tolist()\n",
    "\n",
    "            values = []\n",
    "            for col in columns:\n",
    "                value = row[col]\n",
    "\n",
    "                if pd.isna(value):\n",
    "                    values.append(\"NULL\")\n",
    "\n",
    "                elif isinstance(value, str):\n",
    "                    values.append(f\"'{value.replace(\"'\", \"''\")}'\")\n",
    "\n",
    "                else:\n",
    "                    values.append(str(value))\n",
    "\n",
    "            column_names = \", \".join(columns)\n",
    "            value_string = \", \".join(values)\n",
    "            query = f\"INSERT INTO {table_name} ({column_names}) VALUES ({value_string})\"\n",
    "\n",
    "            export_cursor.execute(query)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error in table: {table_name}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "export_conn.commit()\n",
    "export_cursor.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
