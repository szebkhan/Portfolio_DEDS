{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e2a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def one_hot(index, size):\n",
    "    vec = [0] * size\n",
    "    vec[index] = 1\n",
    "    return vec\n",
    "\n",
    "image_data = {\n",
    "    \"A\": [\n",
    "        [0,1,0],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    \"L\": [\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    \"0\": [\n",
    "        [1,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "    ],\n",
    "    \"1\": [\n",
    "        [0,1,0],\n",
    "        [1,1,0],\n",
    "        [0,1,0]\n",
    "    ],\n",
    "    \"T\": [\n",
    "        [1,1,1],\n",
    "        [0,1,0],\n",
    "        [0,1,0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "def add_noise(image, count=10):\n",
    "    variants = []\n",
    "    for _ in range(count):\n",
    "        variant = np.array(image) + np.random.randint(0, 2, (3, 3))\n",
    "        variant = np.clip(variant, 0, 1)\n",
    "        variants.append(variant.flatten())\n",
    "    return variants\n",
    "\n",
    "classes = list(image_data.keys())\n",
    "X = []\n",
    "y = []\n",
    "for label_index, label in enumerate(classes):\n",
    "    base_image = image_data[label]\n",
    "    variants = add_noise(base_image, count=10)\n",
    "    X.extend(variants)\n",
    "    y.extend([one_hot(label_index, len(classes)) for _ in variants])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e68bd0",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6857c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3155\n",
      "Epoch 100, Loss: 0.0820\n",
      "Epoch 200, Loss: 0.0660\n",
      "Epoch 300, Loss: 0.0593\n",
      "Epoch 400, Loss: 0.0562\n",
      "Epoch 500, Loss: 0.0544\n",
      "Epoch 600, Loss: 0.0531\n",
      "Epoch 700, Loss: 0.0518\n",
      "Epoch 800, Loss: 0.0507\n",
      "Epoch 900, Loss: 0.0499\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        output_error = output - y\n",
    "        output_delta = output_error * sigmoid_derivative(output)\n",
    "\n",
    "        hidden_error = np.dot(output_delta, self.W2.T)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.a1)\n",
    "\n",
    "        self.W2 -= np.dot(self.a1.T, output_delta) * learning_rate\n",
    "        self.b2 -= np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.W1 -= np.dot(X.T, hidden_delta) * learning_rate\n",
    "        self.b1 -= np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.1):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                loss = np.mean((y - output) ** 2)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "nn = NeuralNetwork(input_size=9, hidden_size=10, output_size=5)\n",
    "nn.train(X, y, epochs=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00532385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on sample inputs:\n",
      "Expected: A, Predicted: A\n",
      "Expected: L, Predicted: L\n",
      "Expected: 0, Predicted: 0\n",
      "Expected: 1, Predicted: 1\n",
      "Expected: T, Predicted: T\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredictions on sample inputs:\")\n",
    "for i, label in enumerate(classes):\n",
    "    sample = np.array(image_data[label]).flatten().reshape(1, -1)\n",
    "    prediction = nn.predict(sample)\n",
    "    print(f\"Expected: {label}, Predicted: {classes[prediction[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3de1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
